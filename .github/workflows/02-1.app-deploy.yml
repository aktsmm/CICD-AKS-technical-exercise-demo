name: 2-1. Build and Deploy Application

on:
  # ã‚¢ãƒ—ãƒªã‚³ãƒ¼ãƒ‰ã®ã¿ã®å¤‰æ›´æ™‚ã¯ç›´æ¥å®Ÿè¡Œ
  push:
    branches:
      - main
    paths:
      - "app/**"
      - ".github/workflows/02-1.app-deploy.yml"
  workflow_dispatch:
  # Infrastructureå®Œäº†å¾Œã«è‡ªå‹•å®Ÿè¡Œ
  workflow_run:
    workflows: ["1. Deploy Infrastructure"]
    types:
      - completed
    branches:
      - main

permissions:
  contents: read
  security-events: write

env:
  IMAGE_NAME: ${{ vars.IMAGE_NAME }}
  RESOURCE_GROUP: ${{ vars.AZURE_RESOURCE_GROUP }}

jobs:
  quality-check:
    name: Lint and Unit Tests
    runs-on: ubuntu-latest
    if: ${{ github.event_name != 'workflow_run' || github.event.workflow_run.conclusion == 'success' }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: "20"

      - name: Install Dependencies
        working-directory: app
        run: npm ci

      - name: Run Lint and Tests
        working-directory: app
        run: npm test -- --runInBand --json --outputFile=../test-results.json --reporters=default

      - name: Publish Test Summary
        if: always()
        run: |
          node <<'EOF'
          const fs = require('fs');
          const path = require('path');
          const summaryFile = process.env.GITHUB_STEP_SUMMARY;
          const resultsPath = path.join(process.cwd(), 'test-results.json');

          const writeSummary = (content) => {
            fs.appendFileSync(summaryFile, `${content}\n`);
          };

          if (!fs.existsSync(resultsPath)) {
            writeSummary('### ãƒ†ã‚¹ãƒˆçµæœ\nãƒ†ã‚¹ãƒˆçµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚`npm test` ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
            process.exit(0);
          }

          const data = JSON.parse(fs.readFileSync(resultsPath, 'utf-8'));

          const formatDuration = (ms) => {
            if (typeof ms !== 'number' || !Number.isFinite(ms) || ms < 0) {
              return '-';
            }

            if (ms >= 1000) {
              return `${(ms / 1000).toFixed(2)} s`;
            }

            if (ms >= 10) {
              return `${(ms / 1000).toFixed(3)} s`;
            }

            if (ms > 0) {
              return `${ms.toFixed(0)} ms`;
            }

            return '0 ms';
          };

          const totalSuites = data.numTotalTestSuites || 0;
          const passedSuites = data.numPassedTestSuites || 0;
          const failedSuites = data.numFailedTestSuites || 0;
          const totalTests = data.numTotalTests || 0;
          const passedTests = data.numPassedTests || 0;
          const failedTests = data.numFailedTests || 0;
          const skippedTests = data.numPendingTests || 0;

          writeSummary('### ãƒ†ã‚¹ãƒˆçµæœ');
          writeSummary('');
          writeSummary('| æŒ‡æ¨™ | å€¤ |');
          writeSummary('| --- | --- |');
          writeSummary(`| ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ (åˆè¨ˆ/æˆåŠŸ/å¤±æ•—) | ${totalSuites} / ${passedSuites} / ${failedSuites} |`);
          writeSummary(`| ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ (åˆè¨ˆ/æˆåŠŸ/å¤±æ•—/ã‚¹ã‚­ãƒƒãƒ—) | ${totalTests} / ${passedTests} / ${failedTests} / ${skippedTests} |`);
          writeSummary('');

          if (Array.isArray(data.testResults) && data.testResults.length > 0) {
            writeSummary('| ã‚¹ã‚¤ãƒ¼ãƒˆ | æˆåŠŸ | å¤±æ•— | ã‚¹ã‚­ãƒƒãƒ— | å®Ÿè¡Œæ™‚é–“ |');
            writeSummary('| --- | --- | --- | --- | --- |');
            for (const suite of data.testResults) {
              const suiteName = path.relative(process.cwd(), suite.name || '');
              const assertions = suite.assertionResults || [];
              const passed = assertions.filter((a) => a.status === 'passed').length;
              const failed = assertions.filter((a) => a.status === 'failed').length;
              const skipped = assertions.filter((a) => a.status === 'pending').length;
              const runtimeMs = suite?.perfStats?.runtime ?? suite?.duration ?? 0;
              const duration = formatDuration(runtimeMs);
              writeSummary(`| ${suiteName} | ${passed} | ${failed} | ${skipped} | ${duration} |`);
            }
            writeSummary('');
          }

          writeSummary('ãƒ†ã‚¹ãƒˆã®è©³ç´°ãƒ­ã‚°ã¯ "Run Lint and Tests" ã‚¹ãƒ†ãƒƒãƒ—ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚');
          EOF

  codeql-analysis:
    name: CodeQL Analysis
    runs-on: ubuntu-latest
    # Infrastructure ãƒ‡ãƒ—ãƒ­ã‚¤ãŒæˆåŠŸã—ãŸå ´åˆã®ã¿å®Ÿè¡Œ
    if: ${{ github.event_name != 'workflow_run' || github.event.workflow_run.conclusion == 'success' }}
    permissions:
      actions: read
      contents: read
      security-events: write
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: javascript
        continue-on-error: true # âœ… çµ±ä¸€: åˆæœŸåŒ–å¤±æ•—ã§ã‚‚ã‚¸ãƒ§ãƒ–ç¶šè¡Œ

      - name: Install Node.js Dependencies
        working-directory: app
        run: npm ci

      - name: Autobuild
        uses: github/codeql-action/autobuild@v3
        continue-on-error: true # âœ… çµ±ä¸€: ãƒ“ãƒ«ãƒ‰å¤±æ•—ã§ã‚‚ã‚¸ãƒ§ãƒ–ç¶šè¡Œ

      - name: Analyze
        uses: github/codeql-action/analyze@v3
        with:
          category: "/language:javascript"
        continue-on-error: true # âœ… çµ±ä¸€: è§£æå¤±æ•—ã§ã‚‚ã‚¸ãƒ§ãƒ–ç¶šè¡Œ

      - name: Summarize CodeQL Findings
        if: always()
        run: |
          node <<'EOF'
          const fs = require('fs');
          const path = require('path');
          const zlib = require('zlib');

          const summaryFile = process.env.GITHUB_STEP_SUMMARY;
          const workspace = process.cwd();

          const append = (line = '') => {
            fs.appendFileSync(summaryFile, `${line}\n`);
          };

          append('### CodeQL è§£æçµæœ');
          const envSarifDirRaw = process.env.CODEQL_ACTION_SARIF_RESULTS_OUTPUT_DIR;
          const resolvedEnvSarifDir = envSarifDirRaw
            ? path.resolve(workspace, envSarifDirRaw)
            : null;

          const preferredFiles = [
            path.join(workspace, 'codeql-results', 'javascript.sarif'),
            path.join(workspace, 'codeql-results', 'codeql.sarif'),
            path.join(workspace, 'codeql-results.sarif'),
            resolvedEnvSarifDir ? path.join(resolvedEnvSarifDir, 'javascript.sarif') : null,
            resolvedEnvSarifDir ? path.join(resolvedEnvSarifDir, 'codeql.sarif') : null,
            resolvedEnvSarifDir ? path.join(resolvedEnvSarifDir, 'results.sarif') : null,
          ].filter(Boolean);

          const preferredDirs = [
            path.join(workspace, 'codeql-results'),
            path.join(workspace, 'sarif-results'),
            path.join(workspace, 'results'),
            path.resolve(workspace, '..', 'results'),
            resolvedEnvSarifDir,
            path.join(process.env.RUNNER_TEMP || '', 'codeql_databases'),
          ].filter(Boolean);

          const skipDirNames = new Set(['.git', '.github', 'node_modules', 'rendered']);
          const visited = new Set();

          const findSarifFile = () => {
            for (const candidate of preferredFiles) {
              if (candidate && fs.existsSync(candidate)) {
                return candidate;
              }
              if (candidate && candidate.endsWith('.sarif')) {
                const gzCandidate = `${candidate}.gz`;
                if (fs.existsSync(gzCandidate)) {
                  return gzCandidate;
                }
              }
            }

            const queue = [...preferredDirs];
            const maxDepth = 5;
            const dirsWithDepth = queue.map((dir) => ({ dir, depth: 0 }));

            while (dirsWithDepth.length) {
              const { dir, depth } = dirsWithDepth.shift();
              if (!dir || visited.has(dir)) continue;
              visited.add(dir);

              let entries = [];
              try {
                entries = fs.readdirSync(dir, { withFileTypes: true });
              } catch (error) {
                continue;
              }

              for (const entry of entries) {
                const entryPath = path.join(dir, entry.name);
                if (entry.isDirectory()) {
                  if (depth < maxDepth && !skipDirNames.has(entry.name)) {
                    dirsWithDepth.push({ dir: entryPath, depth: depth + 1 });
                  }
                  continue;
                }

                if (entry.name.endsWith('.sarif') || entry.name.endsWith('.sarif.gz')) {
                  return entryPath;
                }
              }
            }

            return null;
          };

          const sarifFile = findSarifFile();

          if (!sarifFile) {
            append('è§£æçµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚`Analyze` ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
            append();
            process.exit(0);
          }

          const loadSarif = (file) => {
            let buffer = fs.readFileSync(file);
            if (file.endsWith('.gz')) {
              buffer = zlib.gunzipSync(buffer);
            }
            return JSON.parse(buffer.toString('utf-8'));
          };

          let sarif;
          try {
            sarif = loadSarif(sarifFile);
          } catch (error) {
            append(`SARIF ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error.message}`);
            append();
            process.exit(0);
          }

          append(`ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«: \`${path.relative(workspace, sarifFile) || sarifFile}\``);
          append();

          const results = sarif?.runs?.[0]?.results ?? [];
          const errorResults = results.filter((item) => (item?.level || 'none') === 'error');

          append(`Level=error ã®æ¤œå‡ºæ•°: **${errorResults.length}**`);
          append();

          if (errorResults.length === 0) {
            append('Level=error ã®æ¤œå‡ºã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è©³ç´°ã¯ Code Scanning Alerts ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚');
            append();
            process.exit(0);
          }

          const severityOrder = ['Critical', 'High', 'Medium', 'Low', 'Other'];
          const severityCounts = Object.fromEntries(severityOrder.map((k) => [k, 0]));

          for (const item of errorResults) {
            const severityRaw = item?.properties?.securitySeverity || item?.properties?.severity;
            const severityKey = severityOrder.includes(severityRaw) ? severityRaw : 'Other';
            severityCounts[severityKey] += 1;
          }

          append('| Severity (Level=error) | Count |');
          append('| --- | --- |');
          for (const key of severityOrder) {
            append(`| ${key} | ${severityCounts[key]} |`);
          }
          append();

          append('è©³ç´°ã¯ Code Scanning Alerts ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚');
          append();
          EOF

  scan-container:
    name: Scan Container Image
    runs-on: ubuntu-latest
    # Infrastructure ãƒ‡ãƒ—ãƒ­ã‚¤ãŒæˆåŠŸã—ãŸå ´åˆã®ã¿å®Ÿè¡Œ
    if: ${{ github.event_name != 'workflow_run' || github.event.workflow_run.conclusion == 'success' }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Build Docker Image (for scanning)
        run: |
          cd app
          docker build -t ${{ env.IMAGE_NAME }}:${{ github.sha }} .

      - name: Run Trivy Vulnerability Scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.IMAGE_NAME }}:${{ github.sha }}
          format: "sarif"
          output: "trivy-results.sarif"
          severity: "CRITICAL,HIGH"
          exit-code: 0 # âœ… çµ±ä¸€: æ¤œå‡ºãŒã‚ã£ã¦ã‚‚exit code 0
        continue-on-error: true # âœ… çµ±ä¸€: ã‚¹ã‚­ãƒ£ãƒ³å¤±æ•—ã§ã‚‚ã‚¸ãƒ§ãƒ–ç¶šè¡Œ

      - name: Upload Trivy Results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        continue-on-error: true
        with:
          sarif_file: trivy-results.sarif

      - name: Summarize Trivy Findings
        if: always()
        run: |
          node <<'EOF'
          const fs = require('fs');
          const path = require('path');

          const summaryFile = process.env.GITHUB_STEP_SUMMARY;
          const sarifPath = path.join(process.cwd(), 'trivy-results.sarif');

          const append = (line = '') => {
            fs.appendFileSync(summaryFile, `${line}\n`);
          };

          append('### Trivy ã‚¹ã‚­ãƒ£ãƒ³çµæœ');

          if (!fs.existsSync(sarifPath)) {
            append('Trivy ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚`Run Trivy Vulnerability Scanner` ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
            append();
            process.exit(0);
          }

          const sarif = JSON.parse(fs.readFileSync(sarifPath, 'utf-8'));
          const results = sarif?.runs?.[0]?.results ?? [];
          const errorResults = results.filter((item) => (item?.level || 'none').toLowerCase() === 'error');

          append(`Level=error ã®æ¤œå‡ºæ•°: **${errorResults.length}**`);
          append();

          if (errorResults.length === 0) {
            append('Level=error ã®æ¤œå‡ºã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è©³ç´°ã¯ Container Scanning ãƒ¬ãƒãƒ¼ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚');
            append();
            process.exit(0);
          }

          const severityCounts = {};
          const errorDetails = [];

          for (const item of errorResults) {
            const severityRaw = item?.properties?.severity || item?.properties?.securitySeverity || 'UNKNOWN';
            const severityKey = String(severityRaw).toUpperCase();
            severityCounts[severityKey] = (severityCounts[severityKey] || 0) + 1;

            const ruleId = item?.ruleId || 'Unknown rule';
            const message = item?.message?.text || item?.message || 'è©³ç´°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç„¡ã—';
            const location = item?.locations?.[0]?.physicalLocation?.artifactLocation?.uri || '';
            const trimmedLocation = location ? ` (${location})` : '';
            errorDetails.push(`- **${severityKey}** ${ruleId}: ${message}${trimmedLocation}`);
          }

          append('| Severity (Level=error) | Count |');
          append('| --- | --- |');
          for (const [key, value] of Object.entries(severityCounts)) {
            append(`| ${key} | ${value} |`);
          }
          append();

          append('ã‚¨ãƒ©ãƒ¼è©³ç´° (æœ€å¤§10ä»¶):');
          const maxItems = 10;
          errorDetails.slice(0, maxItems).forEach((entry) => append(entry));
          if (errorDetails.length > maxItems) {
            append(`...ä»– ${errorDetails.length - maxItems} ä»¶ã® error ãŒã‚ã‚Šã¾ã™ã€‚`);
          }
          append();

          append('è©³ç´°ãªä¸€è¦§ã¯ Security ã‚¿ãƒ–ã® Container Scanning ãƒ¬ãƒãƒ¼ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚');
          append();
          EOF

  build-push:
    name: Build and Push to ACR
    runs-on: ubuntu-latest
    needs:
      - scan-container
      - codeql-analysis
      - quality-check
    # Infrastructure ãƒ‡ãƒ—ãƒ­ã‚¤ãŒæˆåŠŸã—ãŸå ´åˆã®ã¿å®Ÿè¡Œ
    if: ${{ github.event_name != 'workflow_run' || github.event.workflow_run.conclusion == 'success' }}
    outputs:
      image_tag: ${{ steps.image.outputs.tag }}
      acr_name: ${{ steps.get_acr.outputs.acr_name }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Azure Login (Service Principal)
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Get ACR Name
        id: get_acr
        run: |
          # ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã®å­˜åœ¨ç¢ºèªï¼ˆæœ€å¤§10å›ãƒªãƒˆãƒ©ã‚¤ã€30ç§’é–“éš”ï¼‰
          max_attempts=10
          attempt=1

          while [ $attempt -le $max_attempts ]; do
              echo "ğŸ” Attempt $attempt/$max_attempts: Checking resource group..."
              
              if az group show --name ${{ env.RESOURCE_GROUP }} &>/dev/null; then
                  echo "âœ… Resource group ${{ env.RESOURCE_GROUP }} found!"
                  break
              fi
              
              if [ $attempt -eq $max_attempts ]; then
                  echo "âŒ Resource group ${{ env.RESOURCE_GROUP }} not found after $max_attempts attempts!"
                  echo "Infrastructure deployment may not have completed yet."
                  exit 1
              fi
              
              echo "â³ Resource group not found. Waiting 30 seconds..."
              sleep 30
              attempt=$((attempt + 1))
          done

          # ACRã®å–å¾—ï¼ˆæœ€å¤§20å›ãƒªãƒˆãƒ©ã‚¤ã€30ç§’é–“éš” = æœ€å¤§10åˆ†å¾…æ©Ÿï¼‰
          max_acr_attempts=20
          acr_attempt=1
          ACR_NAME=""

          while [ $acr_attempt -le $max_acr_attempts ]; do
              echo "ğŸ” Attempt $acr_attempt/$max_acr_attempts: Checking ACR..."
              
              ACR_NAME=$(az acr list --resource-group ${{ env.RESOURCE_GROUP }} --query "[0].name" -o tsv)
              
              if [ -n "$ACR_NAME" ]; then
                  echo "âœ… ACR found: ${ACR_NAME}"
                  break
              fi
              
              if [ $acr_attempt -eq $max_acr_attempts ]; then
                  echo "âŒ No ACR found in resource group ${{ env.RESOURCE_GROUP }} after $max_acr_attempts attempts!"
                  echo "Infrastructure deployment may still be in progress."
                  echo "ğŸ’¡ Hint: ACR creation typically takes 5-10 minutes after resource group creation."
                  exit 1
              fi
              
              echo "â³ ACR not found yet. Waiting 30 seconds... (This is normal, ACR creation takes time)"
              sleep 30
              acr_attempt=$((acr_attempt + 1))
          done

          echo "ACR Name: ${ACR_NAME}"
          echo "acr_name=${ACR_NAME}" >> $GITHUB_OUTPUT

      - name: Login to ACR
        run: |
          az acr login --name ${{ steps.get_acr.outputs.acr_name }}

      - name: Build and Push Image
        id: image
        run: |
          cd app
          IMAGE_TAG="${{ github.sha }}"
          ACR_NAME="${{ steps.get_acr.outputs.acr_name }}"
          FULL_IMAGE="${ACR_NAME}.azurecr.io/${{ env.IMAGE_NAME }}:${IMAGE_TAG}"

          docker build -t $FULL_IMAGE .
          docker push $FULL_IMAGE

          # Tag as latest
          docker tag $FULL_IMAGE ${ACR_NAME}.azurecr.io/${{ env.IMAGE_NAME }}:latest
          docker push ${ACR_NAME}.azurecr.io/${{ env.IMAGE_NAME }}:latest

          echo "tag=${IMAGE_TAG}" >> $GITHUB_OUTPUT

  deploy-aks:
    name: Deploy to AKS
    runs-on: ubuntu-latest
    needs: build-push
    # Infrastructure ãƒ‡ãƒ—ãƒ­ã‚¤ãŒæˆåŠŸã—ãŸå ´åˆã®ã¿å®Ÿè¡Œ
    if: ${{ github.event_name != 'workflow_run' || github.event.workflow_run.conclusion == 'success' }}
    environment:
      name: aks-demo
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Azure Login (Service Principal)
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Get Infrastructure Details
        id: infra
        run: |
          echo "Querying Azure for infrastructure details..."

          # AKSã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åã‚’å–å¾—
          AKS_CLUSTER_NAME=$(az aks list -g ${{ env.RESOURCE_GROUP }} --query "[0].name" -o tsv)

          # MongoDB VMã®ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆIPã‚’å–å¾—ï¼ˆVNetå†…é€šä¿¡ç”¨ï¼‰
          MONGO_VM_IP=$(az vm list-ip-addresses -g ${{ env.RESOURCE_GROUP }} -n vm-mongo-dev --query "[0].virtualMachine.network.privateIpAddresses[0]" -o tsv)

          echo "AKS Cluster: ${AKS_CLUSTER_NAME}"
          echo "MongoDB VM IP: ${MONGO_VM_IP}"

          echo "aks_name=${AKS_CLUSTER_NAME}" >> $GITHUB_OUTPUT
          echo "mongo_ip=${MONGO_VM_IP}" >> $GITHUB_OUTPUT

      - name: Wait for AKS API to Become Ready
        run: |
          RG='${{ env.RESOURCE_GROUP }}'
          CLUSTER='${{ steps.infra.outputs.aks_name }}'

          if [ -z "$CLUSTER" ]; then
            echo "AKS cluster name is empty. Ensure infrastructure deployment completed."
            exit 1
          fi

          echo "Waiting for AKS control plane to reach Succeeded state..."
          max_attempts=30
          attempt=1

          while [ $attempt -le $max_attempts ]; do
            state=$(az aks show --resource-group "$RG" --name "$CLUSTER" --query provisioningState -o tsv)
            echo "Attempt $attempt/$max_attempts => $state"

            if [ "$state" == "Succeeded" ]; then
              echo "AKS provisioning completed."
              break
            fi

            if [ "$state" == "Failed" ]; then
              echo "AKS provisioning failed. Aborting deployment."
              exit 1
            fi

            if [ $attempt -eq $max_attempts ]; then
              echo "AKS did not reach Succeeded within expected time."
              exit 1
            fi

            sleep 30
            attempt=$((attempt + 1))
          done

      - name: Prepare Kubernetes Manifests
        env:
          ACR_NAME: ${{ needs.build-push.outputs.acr_name }}
          IMAGE_TAG: ${{ needs.build-push.outputs.image_tag }}
        run: |
          mkdir -p rendered
          cp app/k8s/deployment.yaml rendered/deployment.yaml
          cp app/k8s/service.yaml rendered/service.yaml
          cp app/k8s/ingress.yaml rendered/ingress.yaml
          cp app/k8s/rbac-vulnerable.yaml rendered/rbac-vulnerable.yaml
          cp app/k8s/ingress-nginx-controller.yaml rendered/ingress-nginx-controller.yaml

          sed -i "s|<ACR_NAME>|${ACR_NAME}|g" rendered/deployment.yaml
          sed -i "s|<IMAGE_NAME>|${{ env.IMAGE_NAME }}|g" rendered/deployment.yaml
          sed -i "s|<IMAGE_TAG>|${IMAGE_TAG}|g" rendered/deployment.yaml

      - name: Render Mongo Credentials Secret
        env:
          MONGO_ADMIN_PASSWORD: ${{ secrets.MONGO_ADMIN_PASSWORD }}
        run: |
          mkdir -p rendered
          cat <<'EOF' > rendered/mongo-secret.yaml
          apiVersion: v1
          kind: Secret
          metadata:
            name: mongo-credentials
            namespace: default
          type: Opaque
          stringData:
            uri: PLACEHOLDER
            username: mongoadmin
          EOF

          URI="mongodb://mongoadmin:${MONGO_ADMIN_PASSWORD}@${{ steps.infra.outputs.mongo_ip }}:27017/guestbook?authSource=admin"
          sed -i "s|PLACEHOLDER|${URI}|g" rendered/mongo-secret.yaml

      - name: Apply Core Manifests via AKS Command Invoke
        run: |
          RG='${{ env.RESOURCE_GROUP }}'
          CLUSTER='${{ steps.infra.outputs.aks_name }}'

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl apply -f mongo-secret.yaml" \
            --file rendered/mongo-secret.yaml

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl apply -f ingress-nginx-controller.yaml" \
            --file rendered/ingress-nginx-controller.yaml

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl apply -f rbac-vulnerable.yaml" \
            --file rendered/rbac-vulnerable.yaml

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl apply -f deployment.yaml" \
            --file rendered/deployment.yaml

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl apply -f service.yaml" \
            --file rendered/service.yaml

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl apply -f ingress.yaml" \
            --file rendered/ingress.yaml

      - name: Wait for Deployment via Control Plane
        run: |
          RG='${{ env.RESOURCE_GROUP }}'
          CLUSTER='${{ steps.infra.outputs.aks_name }}'

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl wait --namespace ingress-nginx --for=condition=ready pod --selector=app.kubernetes.io/component=controller --timeout=120s" \
            || echo "âš ï¸ Ingress Controller readiness timed out"

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl rollout status deployment/guestbook-app --timeout=5m"

      - name: Configure HTTPS with cert-manager
        id: tls
        run: |
          RG='${{ env.RESOURCE_GROUP }}'
          CLUSTER='${{ steps.infra.outputs.aks_name }}'

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.2/cert-manager.yaml"

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl wait --namespace cert-manager --for=condition=ready pod --selector=app.kubernetes.io/instance=cert-manager --timeout=120s" \
            || echo "âš ï¸ cert-manager readiness timed out"

          cat <<'EOF' > rendered/cluster-issuer.yaml
          apiVersion: cert-manager.io/v1
          kind: ClusterIssuer
          metadata:
            name: selfsigned-issuer
          spec:
            selfSigned: {}
          EOF

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl apply -f cluster-issuer.yaml" \
            --file rendered/cluster-issuer.yaml

          INGRESS_IP=$(az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}'" \
            --query "logs" -o tsv)

          if [ -z "$INGRESS_IP" ]; then
            echo "â³ Waiting for External IP..."
            sleep 30
            INGRESS_IP=$(az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
              --command "kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}'" \
              --query "logs" -o tsv)
          fi

          if [ -z "$INGRESS_IP" ]; then
            echo "âŒ Could not get Ingress IP. Skipping TLS configuration."
            exit 0
          fi

          DOMAIN="${INGRESS_IP}.nip.io"
          echo "ğŸ“¡ Using domain: ${DOMAIN}"

          echo "ip=${INGRESS_IP}" >> $GITHUB_OUTPUT

          cat <<EOF > rendered/ingress-tls.yaml
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: guestbook-ingress
            namespace: default
            annotations:
              nginx.ingress.kubernetes.io/rewrite-target: /
              nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
              cert-manager.io/cluster-issuer: selfsigned-issuer
          spec:
            ingressClassName: nginx
            tls:
              - hosts:
                  - ${DOMAIN}
                secretName: guestbook-tls-cert
            rules:
              - host: ${DOMAIN}
                http:
                  paths:
                    - path: /
                      pathType: Prefix
                      backend:
                        service:
                          name: guestbook-service
                          port:
                            number: 80
              - http:
                  paths:
                    - path: /
                      pathType: Prefix
                      backend:
                        service:
                          name: guestbook-service
                          port:
                            number: 80
          EOF

          az aks command invoke --resource-group "$RG" --name "$CLUSTER" \
            --command "kubectl apply -f ingress-tls.yaml" \
            --file rendered/ingress-tls.yaml

          echo "domain=${DOMAIN}" >> $GITHUB_OUTPUT

      - name: Publish Deployment Summary
        env:
          SUMMARY_DOMAIN: ${{ steps.tls.outputs.domain }}
          SUMMARY_IP: ${{ steps.tls.outputs.ip }}
          INGRESS_IP_JSON: ${{ steps.tls.outputs.raw_result }}
        run: |
          set -euo pipefail
          RG='${{ env.RESOURCE_GROUP }}'
          CLUSTER='${{ steps.infra.outputs.aks_name }}'

          PODS='âš ï¸ kubectl ã‹ã‚‰ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ'
          if POD_OUTPUT=$(az aks command invoke --resource-group "$RG" --name "$CLUSTER" --command "kubectl get pods -n default -l app=guestbook -o wide" --query "logs" -o tsv 2>&1); then
            PODS="$POD_OUTPUT"
          else
            echo "âš ï¸ az aks command invoke ã§ Pod æƒ…å ±å–å¾—ã«å¤±æ•—: $POD_OUTPUT"
          fi

          DOMAIN_LINE="${SUMMARY_DOMAIN}"
          if [ -z "$DOMAIN_LINE" ]; then
            DOMAIN_LINE='Pending IP allocation'
          fi

          HTTPS_URL='Pending IP allocation'
          if [ -n "$SUMMARY_DOMAIN" ]; then
            HTTPS_URL="https://$SUMMARY_DOMAIN"
          fi

          HTTP_URL='Pending IP allocation'
          if [ -n "$SUMMARY_IP" ]; then
            HTTP_URL="http://$SUMMARY_IP"
          else
            RAW=$(echo "$INGRESS_IP_JSON" | awk -F'[\[\]]' '{print $2}' | awk -F"'" '{print $2}')
            if [ -z "$RAW" ]; then
              # ARM API ã‹ã‚‰ Public IP ã‚’å–å¾—ã—ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¡¨ç¤º
              NODE_RG=$(az aks show --resource-group "$RG" --name "$CLUSTER" --query nodeResourceGroup -o tsv)
              RAW=$(az network public-ip list --resource-group "$NODE_RG" --query "[?ipAddress!='' ].ipAddress | [0]" -o tsv || true)
            fi
            if [ -n "$RAW" ]; then
              HTTP_URL="http://$RAW"
            fi
          fi

          {
            echo "### Deployment Summary"
            echo "- Cluster: ${CLUSTER}"
            echo "- Mongo VM IP: ${{ steps.infra.outputs.mongo_ip }}"
            echo "- Domain: ${DOMAIN_LINE}"
            echo "- HTTPS: ${HTTPS_URL}"
            echo "- HTTP: ${HTTP_URL}"
            echo "- Image: ${{ needs.build-push.outputs.acr_name }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ needs.build-push.outputs.image_tag }}"
            echo "- Pods:" 
            echo '```'
            echo "$PODS"
            echo '```'
          } >> $GITHUB_STEP_SUMMARY

          # Exit here to prevent legacy inline commands from executing
          exit 0
